#!/usr/bin/env python@TECA_PYTHON_VERSION@
from teca import *
import sys
import argparse
import numpy as np
try:
    from mpi4py import MPI
    comm = MPI.COMM_WORLD
    rank = comm.Get_rank()
    n_ranks = comm.Get_size()
except ImportError:
    rank = 0

# parse the command line
parser = argparse.ArgumentParser()
parser.add_argument('--input_file', type=str, required=False,
    help='file path to the simulation to search for atmospheric rivers')

parser.add_argument('--input_regex', type=str, required=False,
    help='regex matching simulation files to search for atmospheric rivers')

parser.add_argument('--output_file', type=str, required=False,
    default=r'deeplabv3p_ar_detect_%t%.nc',
    help=r'file pattern for output netcdf files (%%t%% is the time index)')

parser.add_argument('--ivt', type=str, default='IVT',
    help='name of variable with integrated vapor transport (IVT)')

parser.add_argument('--n_threads', type=int, default=-1,
    help='number of threads used in torch for parallelizing CPU operations')

parser.add_argument('--binary_ar_threshold', type=float,
    default=0.6666666667, help='probability threshold for segmenting'
    'ar_probability to produce ar_binary_tag')

parser.add_argument('--pytorch_deeplab_model', type=str, required=False,
    help='the pretrained deeplabv3plus model file')

parser.add_argument('--t_axis_variable', type=str, required=False,
    help='time dimension name')

parser.add_argument('--t_calendar', type=str, required=False,
    help='time calendar')

parser.add_argument('--t_units', type=str, required=False,
    help='time unit')

parser.add_argument('--filename_time_template', type=str, required=False,
    help='filename time template')

parser.add_argument('--compression_level', type=int, required=False,
    help='the compression level used for each variable')

parser.add_argument('--date_format', type=str, required=False,
    help='the format for the date to write in the filename')

parser.add_argument('--first_step', type=int, required=False,
    help='first time step to process')

parser.add_argument('--last_step', type=int, required=False,
    help='last time step to process')

parser.add_argument('--steps_per_file', type=int, required=False,
    help='number of time steps per output file')

parser.add_argument('--start_date', type=str, required=False,
    help='first time to proces in YYYY-MM-DD hh:mm:ss format')

parser.add_argument('--end_date', type=str, required=False,
    help='end time to proces in YYYY-MM-DD hh:mm:ss format')

args = parser.parse_args()

# create the reader
if args.input_file:
    reader = teca_multi_cf_reader.New()
    reader.set_file_name(args.input_file)
elif args.input_regex:
    reader = teca_cf_reader.New()
    reader.set_files_regex(args.input_regex)
else:
    if rank == 0:
        raise RuntimeError('Exactly one of --input_file or --input_regex'
                           ' must be provided')

coords = teca_normalize_coordinates.New()
coords.set_input_connection(reader.get_output_port())

deeplabv3p_ar_detect = teca_deeplabv3p_ar_detect.New()
deeplabv3p_ar_detect.set_input_connection(coords.get_output_port())

seg_atts = teca_metadata()
seg_atts["long_name"] = "binary indicator of atmospheric river"
seg_atts["description"] = "binary indicator of atmospheric river"
seg_atts["scheme"] = "cascade_bard"
seg_atts["version"] = "1.0"
seg_atts["note"] = "derived by thresholding ar_probability >= %f" \
    % args.binary_ar_threshold

ar_tag = teca_binary_segmentation.New()
ar_tag.set_input_connection(deeplabv3p_ar_detect.get_output_port())
ar_tag.set_threshold_mode(ar_tag.BY_VALUE)
ar_tag.set_threshold_variable("ar_probability")
ar_tag.set_segmentation_variable("ar_binary_tag")
ar_tag.set_low_threshold_value(args.binary_ar_threshold)
ar_tag.set_segmentation_variable_attributes(seg_atts)

cf_writer = teca_cf_writer.New()
cf_writer.set_input_connection(ar_tag.get_output_port())
cf_writer.set_thread_pool_size(1)

if args.output_file:
    cf_writer.set_file_name(args.output_file)

if args.ivt:
    deeplabv3p_ar_detect.set_variable_name(args.ivt)

# set the number of threads. this is particularly fraught
# in MPI parallel mode without checking how many ranks are
# scheduled to each node. Each MPI rank will allocate
# this many threads and performance of the application will
# severely degrade when more than a couple of threads per
# physical core are created. hence the warning
if args.n_threads > 0 and n_ranks > 1:
    if rank == 0:
        sys.stderr.write('WARNING: Command line setting %d threads per MPI '
                         'rank may degrade performance!'%(args.n_threads))
deeplabv3p_ar_detect.set_thread_pool_size(args.n_threads)

if args.pytorch_deeplab_model:
    deeplabv3p_ar_detect.build_model(args.pytorch_deeplab_model)
else:
    deeplabv3p_ar_detect.build_model()

if args.t_axis_variable is not None:
    reader.set_t_axis_variable(args.t_axis_variable)

if args.t_calendar:
    reader.set_t_calendar(args.t_calendar)

if args.t_units:
    reader.set_t_units(args.t_units)

if args.filename_time_template:
    reader.set_filename_time_template(args.filename_time_template)

if args.compression_level:
    cf_writer.set_compression_level(args.compression_level)

if args.date_format:
    cf_writer.set_date_format(args.date_format)

if args.first_step:
    cf_writer.set_first_step(args.first_step)

if args.last_step:
    cf_writer.set_last_step(args.last_step)

if args.steps_per_file:
    cf_writer.set_steps_per_file(args.steps_per_file)

if args.start_date or args.end_date:

    time_atts = atrs["time"]
    calendar = time_atts["calendar"]
    units = time_atts["units"]

    coords = md["coordinates"]
    time = coords["t"]

    # convert date string to step, start date
    if args.start_date:
        first_step = coordinate_util.time_step_of(time, True, True, calendar,
                                                  units, args.start_date)
        cf_writer.set_first_step(first_step)

    # and end date
    if args.end_date:
        last_step = coordinate_util.time_step_of(time, False, True, calendar,
                                                 units, args.end_date)
        cf_writer.set_last_step(last_step)

# run the pipeline
exe = teca_index_executive.New()
cf_writer.set_executive(exe)
cf_writer.set_point_arrays(['ar_probability', 'ar_binary_tag'])

cf_writer.update()
